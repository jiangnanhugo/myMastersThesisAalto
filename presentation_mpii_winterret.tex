\documentclass{beamer}
\usetheme{Frankfurt}
\usecolortheme{beaver}
\setbeamertemplate{caption}{\raggedright\insertcaption\par}
\setlength{\itemsep}{\fill}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{longtable}

\def\cvs{${[}$Id: slides.tex,v 1.19 2015/12/09 16:42:43 shettyr1 Exp ${]}$}

%\beamertemplatenavigationsymbolsempty
\bibliographystyle{acm}

\newcommand{\slide}[1]{\scalebox{1.0}{\includegraphics[page=#1]{slides}}}
\newcommand{\mct}[1]{\multicolumn{2}{c|}{\bf#1}}
\newcommand{\mcCell}[1]{\multicolumn{1}{|c|}{#1}}
\newcommand{\bs}{\small\bf}
\newcommand{\red}[1]{\protect\begin{color}{red}#1\protect\end{color}}
\newcommand{\green}[1]{\protect\begin{color}{green}#1\protect\end{color}}
\newcommand{\mlhead}[2]{%
    \parbox[c][][c]{#1}{\smallskip\centering #2 \smallskip}
    }
\begin{document}

%%-----------------------------------------------------------------------------

\title{Adversarial Generation of Discrete Sequences for Image Captioning}
%\subtitle{Winter Retreat Talk}
\author[Rakshith Shetty]{Rakshith Shetty\\[4mm] {\small PhD Student}}
\institute{Max Planck Institute of Informatics}
\date{\today}

\frame{\titlepage} 

\section{My Background}
%%-----------------------------------------------------------------------------

\begin{frame}{Hello!}
  \begin{itemize}
    \item One week old PhD student at MPI-INF :-)
    \item Master's in Machine Learning and Data Mining 
        \begin{itemize}
            \item Aalto University, Helsinki, Finland
        \end{itemize}
    \item Bachelor's -- Electronics and Signal Processing 
    \item Three years work experience at Broadcom (Wifi/ LTE)
  \end{itemize}
\end{frame}

%%-----------------------------------------------------------------------------
%\begin{frame}{Understanding Visual Media}
%  \begin{itemize}
%  \item<1-> Images = \{objects, attributes, relations\}\\
%  \begin{figure}[h]
%    \begin{columns}
%    \column{.5\linewidth}
%    %\hspace{-8mm}%
%    \hfill\includegraphics[width=0.6\textwidth]{images/COCO_train2014_000000544856.jpg}
%    \hspace{-5mm}\column{.5\linewidth}
%    \centering
%    \caption{a giraffe walking through a patch of high dried out grass.}
%    \end{columns}
%  \end{figure}
%  \item<1->Videos = \{Images + temporal relations\}\\[4mm]
%  \item<1->Humans rely on natural language descriptions
%  \item<1->Can computers generate captions too?
%  \end{itemize}
%\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Summary of My Thesis}
%\includegraphics[width=1\textwidth]{images/VideoCaptionModified.png}
        Title -- \textbf{Natural Language Description of Images and Videos}
\begin{itemize}
\item Focussed on the problem of image and video captioning 
    \begin{itemize}
         \item Given an input image or video, $V$, output a caption, $S$
    \end{itemize}
\item Model -- visual feature encoder + language model 
        \begin{figure}[h]
            \centering
            \includegraphics[width=0.8\textwidth]{images/EncDec.pdf}
        \end{figure}
%\item Image is encoded using CNN features
%\item Video encoding uses a combination of
%    \begin{itemize}
%        \item Frame level features - CNN
%        \item Segment level features - dense trajectories, C3D 
%    \end{itemize}
%\item Language model is based on a recurrent network (LSTM) 
\end{itemize}
\end{frame}

%%-----------------------------------------------------------------------------
\begin{frame}{Key Results from the Thesis}
%\includegraphics[width=1\textwidth]{images/VideoCaptionModified.png}
\begin{itemize}
\item Image encoding is improved by
    \begin{itemize}
        \item Explicit object and scene detection features
    \end{itemize}
\item Language model is improved by 
    \begin{itemize}
        \item Adding additional input channel decoupled from word inputs
        \item Adopting residual connections 
    \end{itemize}
\item Ensemble language models using an evaluator network
    \begin{itemize}
        \item Significantly increases language diversity
        \item Improves performance in video captioning
    \end{itemize}
\item Good results in standard benchmarks
    \begin{itemize}
        \item Won two video captioning competitions: LSMDC-'15 and MSR-VTT'16 
        \item Top of COCO leaderboard, at least for a while
    \end{itemize}
\end{itemize}
\end{frame}

%%=============================================================================
\section{What Next}
%%-----------------------------------------------------------------------------
%\begin{frame}{Up Next.....}
%\tableofcontents[currentsection] 
%\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Some Prominent Problems}
\begin{itemize}
    \item Language model can hallucinate objects
        \begin{itemize}
            \item Need stricter demand for visual evidence? 
        \end{itemize}
    \item There is a length bias in the samples generated
        \begin{itemize}
            \item Shorter sentences are preferred in generated captions 
            \item Worse with larger beamsize~\cite{Sountsov2016LengthBI} 
        \end{itemize}
    \item Sample diversity is poor
        \begin{itemize}
            \item Learns generic and repetitive descriptions 
        \end{itemize}
        \begin{table}[tbh]
          \centering
          \scalebox{0.75}{
          \begin{tabular}{|c|c|c|c|c|}
            \hline
            \bf \# 
            &\mlhead{1.6cm}{ Mean Length}
            &\mlhead{2.1cm}{ Vocabulary\\ Size} 
            &\mlhead{2.1cm}{\% Unique Captions} 
            &\mlhead{2cm}{\% New Captions} \\\hline
            Our best Model & 9.01 & 1112 & 28.43 & 22.04\\\hline
          \end{tabular}
          }
          \caption{Language diversity statistics on test set (on 40k samples)}
          \label{tab:resCocQual}
        \end{table}
\end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Problem with Maximum Likelihood Training}
\begin{itemize}
    \item Training objective is to maximize 
    \begin{equation*}
            \label{eq:langB1}\mathcal{L}(S | V)  = \log(P(S|V)) = P(w_0, w_1, \cdots, w_{L-1}|V)  .
    \end{equation*}
    \item We can factorize this as :
    \begin{equation*}
      \label{eqCost}
      \mathcal{L}(S | V) = \sum_{t=0}^{L-1} \log(p(w_t|w_{t-1},V)) \; ,
    \end{equation*}
    \item Training mode -- ground truth tokens are given at each step
    \item Thus the optimization on "local" transition probabilities
    \item We can't impose sequence level costs
        \begin{itemize}
            \item Network is not generating anything
        \end{itemize}
    \item Test mode -- Left to run on its own!
\end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Alternative Training Methods}
    \begin{itemize}
        \item Scheduled Sampling~\cite{bengio2015scheduled}
            \begin{itemize}
                \item Mix samples from the model with ground truth while training 
            \end{itemize}
        \item Reinforcement learning based methods
            \begin{itemize}
                \item Use RL methods to approximate the gradient of reward for sampled sentences
                \item Large discrete action space depending on vocabulary size
                \item Might need pre-training
            \end{itemize}
        \item Successful application of RL method from IBM team~\cite{rennie2016self}
            \begin{itemize}
                \item Directly optimized a captioning model on CIDEr
                \item Currently top of COCO leaderboard
            \end{itemize}
    \end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Adversarial Training}
    \begin{itemize}
        \item Generator generates a sample $s'$ from $P(S|I)$
        \item Evaluator network scores if $s'$ comes from human 
            \begin{itemize}
                \item Note that this would be a sequence level evaluation
                \item Other sequence level costs can be incorporated
            \end{itemize}
        \item Train them adversarially using backprop
        \item There is a catch! 
            \begin{itemize}
                \item Word samples are discrete variables and are not differentiable.
            \end{itemize}
    \end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Some Solutions in Literature}
    \begin{itemize}
        \item Seq-GANs~\cite{yu2016seqgan} 
            \begin{itemize}
                \item Replace backprop with RL 
                \item RL reward signal comes from the adversary.
            \end{itemize}
        \item Professor Forcing~\cite{lamb2016professor}
            \begin{itemize}
                \item Instead of evaluating samples evaluate hidden state
                \item Evaluator tries to distinguish hidden states b/w training and test mode!
            \end{itemize}
     \end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Let's Do Backprop Anyway!}
    Gumbel Softmax~\cite{jang2016categorical, maddison2016concrete}
    \begin{itemize}
        \item Use Gumbel-Max trick to re-parametrize categorical distribution
        \begin{equation*}
                z = \text{one\_hot}(\text{argmax}_i[\log(\theta_i)+ g_i])
        \end{equation*}
        \item Approximate the $\text{argmax}$ with a $\text{softmax}$ 
        \item Allows back-propagations!
    \end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Possible Benefits of Adversarial Approach}
    \begin{itemize}
        \item Evaluator can impose sequence level penalties 
        \item No discrepancy between training and testing modes 
        \item Batch evaluation could help improve diversity 
        \item Free caption evaluation~\cite{kannan2016}
    \end{itemize}
\end{frame}
%%-----------------------------------------------------------------------------
%\begin{frame}{Looking Forward}
%\begin{itemize}
%    \item Multiple Captions
%       \begin{itemize}
%           \item Complementary captions.
%           \item Paragraph summaries
%           \item Covering entire visual information
%       \end{itemize}
%    \item Scene graphs 
%       \begin{itemize}
%           \item Build graph representing objects, attributes and relations 
%           \item More actionable representation
%       \end{itemize}
%    \item Video features 
%       \begin{itemize}
%           \item Extract and represent long term dependencies in videos
%       \end{itemize}
%    \item Interpretable models
%       \begin{itemize}
%           \item Explain why a particular word is used
%           \item Visually or gramatically ground every word used
%       \end{itemize}
%\end{itemize}
%\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{}
\begin{center}
    \Large Thank You for Listening\\[6mm]
    \Large Any Questions? 
\end{center}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}[allowframebreaks]
        \frametitle{References}
        \bibliography{bib_thesis_used_only}
\end{frame}
%%-----------------------------------------------------------------------------
\section{Extra Material}
%%-----------------------------------------------------------------------------
\begin{frame}{Naive Model}
\begin{figure}[t]
  \begin{center}
      \includegraphics[width=0.8\linewidth]{images/Adverserial.png}
  \end{center}
\end{figure}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Sample Results on COCO}
\begin{figure}[h]
  \begin{center}
  \centering
  %\tabcolsep=0.05cm
  \scalebox{0.7}{
  \begin{tabular}{c|c|c|c|}
          \cline{2-4}
    &\includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000502766.jpg} &
    \includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000161720.jpg} &
    \includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000385707.jpg} \\\hline
    \mcCell{\textbf{\em\scriptsize C27:}}& \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a man and a dog herding sheep in a field\smallskip} &
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a bathroom with a sink toilet and bathtub\smallskip} &
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a bottle of wine and a glass of wine\smallskip}\\\hline
     \mcCell{\textbf{\em\scriptsize C19:}}& \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a man standing next to a herd of sheep\smallskip}&
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a bathroom with a toilet and a sink\smallskip}&
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize two bottles of wine sitting on a table\smallskip}\\\hline
     &\includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000251330.jpg} &
    \includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000218404.jpg} &
    \includegraphics[width=0.25\linewidth,height=2.5cm]{images/COCO_val2014_000000119516.jpg} \\\hline
    \mcCell{\textbf{\em\scriptsize C27:}}& \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a view of a bridge in the snow\smallskip} &
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a table with plates of food on it\smallskip}&
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a person riding a bike down a city street\smallskip}\\\hline
     \mcCell{\textbf{\em\scriptsize C19:}}& \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a train crossing a bridge over a river\smallskip} &
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a table topped with plates of food and drinks\smallskip}&
     \parbox[c][][c]{0.25\linewidth}{\smallskip \scriptsize a city street filled with lots of traffic\smallskip}\\\hline
  \end{tabular}
  }
  \end{center}
  \caption{Captions generated for some images from the COCO validation set by two of our
    models. The first row contains samples where the ensemble model,
    C27, performs better, and the second row cases where C19 is
    better.}
  \label{fig:cococapSamps}
\end{figure}

\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Sample Captions Video}
\begin{figure}[thp]
  \begin{center}
  \centering
  \tabcolsep=0.10cm
  \scalebox{0.7}{
          \begin{tabular}{|l|l|l|}
    \hline
    \mcCell{\includegraphics[width=0.25\linewidth]{images/LsmdcVid0.png}} &
    \mcCell{\includegraphics[width=0.25\linewidth]{images/LsmdcVid1.png}} &
    \mcCell{\includegraphics[width=0.25\linewidth]{images/LsmdcVid2.png}}
    \\\hline
    \textbf{\scriptsize\em L6:} \scriptsize someone runs up to the car&
    \textbf{\scriptsize\em L6:} \scriptsize someone is dancing with her&
    \textbf{\scriptsize\em L6:} \scriptsize someone looks up at the house\\\hline\\\hline
    \mcCell{\includegraphics[width=0.25\linewidth]{images/9150.png}} &
    \mcCell{\includegraphics[width=0.25\linewidth]{images/9799.png}} &
    \mcCell{\includegraphics[width=0.25\linewidth]{images/7997.png}} \\\hline
    \textbf{\scriptsize\em M6:} \scriptsize a man is running in a gym &
    \textbf{\scriptsize\em M6:} \scriptsize a person is playing with a rubix cube &
    \textbf{\scriptsize\em M6:} \scriptsize cartoon characters are interacting\\
    \textbf{\scriptsize\em M2:} \scriptsize a man is running&
    \textbf{\scriptsize\em M2:} \scriptsize a man is holding a phone&
    \textbf{\scriptsize\em M2:} \scriptsize a person is playing a video game\\
    \textbf{\scriptsize\em M5:} \scriptsize a man is playing basketball&
    \textbf{\scriptsize\em M5:} \scriptsize a person is playing with a rubix cube &
    \textbf{\scriptsize\em M5:} \scriptsize a group of people are talking\\
    \hline
  \end{tabular}
  }
  \end{center}
  \label{fig:VttcapSamps}
\end{figure}
\end{frame}
%%-----------------------------------------------------------------------------
\begin{frame}{Qualitative Analysis}
\vspace{-5mm}
\begin{columns}
  \column{.5\linewidth}
  \begin{figure}[t]
    \centering
    \includegraphics[trim={2cm 0 2cm 0},clip,width=0.8\linewidth]{images/VTTCiderCateg.pdf}
    \vspace{-5mm}
    \caption{Performance by video category}%
  \end{figure}
  \column{.5\linewidth}
  \begin{figure}[t]
    \centering
    \includegraphics[trim={2cm 0 2cm 0},clip, width=0.8\linewidth]{images/VTTCiderLengths.pdf}
    \vspace{-5mm}
    \caption{Performance by video length}
    \label{fig:VttLenPerf}
  \end{figure}
\end{columns}
\begin{itemize}
    \item Video category has a huge impact
       \begin{itemize}
               \item \emph{How to}, \emph{video games} perform best 
               \item \emph{News}, \emph{tv} perform worst 
       \end{itemize}
    \item Surprisingly, length doesn't seem effect much (in-conclusive) 
\end{itemize}
\end{frame}
\end{document}
