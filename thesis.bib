@article{AtorabiM-VAD2015,
  author =	 {Torabi, Atousa and Pal Chris and Larochelle Hugo and
                  Courville Aaron},
  title =	 {Using Descriptive Video Services To Create a Large
                  Data Source For Video Annotation Research},
  journal =	 {arXiv preprint},
  year =	 {2015},
  url =		 {http://arxiv.org/pdf/1503.01070v1.pdf}
}

@inproceedings{rohrbach15cvpr,
  title =	 {A Dataset for Movie Description},
  author =	 {Rohrbach, Anna and Rohrbach, Marcus and Tandon,
                  Niket and Schiele, Bernt},
  booktitle =	 {Proceedings of the IEEE Conference on Computer
                  Vision and Pattern Recognition (CVPR)},
  url =
                  {http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Rohrbach_A_Dataset_for_2015_CVPR_paper.pdf},
  year =	 {2015}
}

@InProceedings{Vinyals_2015_CVPR,
  author =	 {Vinyals, Oriol and Toshev, Alexander and Bengio,
                  Samy and Erhan, Dumitru},
  title =	 {Show and Tell: A Neural Image Caption Generator},
  booktitle =	 {Proceedings of the IEEE Conference on Computer
                  Vision and Pattern Recognition (CVPR)},
  month =	 {June},
  year =	 {2015}
}

@inproceedings{DBLP:conf/cvpr/WangKSL11,
  author =	 {Heng Wang and Alexander Kl{\"{a}}ser and Cordelia
                  Schmid and Cheng{-}Lin Liu},
  title =	 {Action recognition by dense trajectories},
  booktitle =	 {Proceedings of the 24th {IEEE} Conference on
                  Computer Vision and Pattern Recognition (CVPR)},
  pages =	 {3169--3176},
  publisher =	 {{IEEE} Computer Society},
  year =	 {2011},
  url =		 {http://dx.doi.org/10.1109/CVPR.2011.5995407},
  doi =		 {10.1109/CVPR.2011.5995407},
  timestamp =	 {Tue, 25 Nov 2014 17:05:17 +0100},
  biburl =
                  {http://dblp2.uni-trier.de/rec/bib/conf/cvpr/WangKSL11},
  bibsource =	 {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/ijcv/WangKSL13,
  author =	 {Heng Wang and Alexander Kl{\"{a}}ser and Cordelia
                  Schmid and Cheng{-}Lin Liu},
  title =	 {Dense Trajectories and Motion Boundary Descriptors
                  for Action Recognition},
  journal =	 {International Journal of Computer Vision},
  volume =	 {103},
  number =	 {1},
  pages =	 {60--79},
  year =	 {2013},
  url =		 {http://dx.doi.org/10.1007/s11263-012-0594-8},
  doi =		 {10.1007/s11263-012-0594-8},
  timestamp =	 {Mon, 29 Apr 2013 12:57:52 +0200},
  biburl =
                  {http://dblp.uni-trier.de/rec/bib/journals/ijcv/WangKSL13},
  bibsource =	 {dblp computer science bibliography, http://dblp.org}
}

@Article{Simonyan14c,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "arXiv",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@article{DBLP:journals/corr/SzegedyLJSRAEVR14,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {arXiv},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  timestamp = {Wed, 01 Oct 2014 15:00:05 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{2015trecvidover,
    author= {Paul Over and George Awad and Martial Michel and Jonathan Fiscus and Wessel Kraaij and Alan F. Smeaton and Georges Quéenot and Roeland Ordelman},
    title = {TRECVID 2015 -- An Overview of the Goals, Tasks, Data, Evaluation Mechanisms and Metrics},
    booktitle = {Proceedings of TRECVID 2015},
    keywords={TRECVid, Video Retrieval, Multimedia Retrieval, IR Evaluation},
    year = 2015,
    organization = {NIST, USA},
    pdf={http://www-nlpir.nist.gov/projects/tvpubs/tv15.papers/tv15overview.pdf},
}

@inproceedings{Karpathy_2015_CVPR,
    author = {Karpathy, Andrej and Fei-Fei, Li},
    title = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
    booktitle = {Proceedings of the IEEE Conference on Computer Vision
                  and Pattern Recognition (CVPR)},
    month = {June},
    year = {2015}
}

@article{Hochreiter1997,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@inproceedings{Lin2014,
   title = {Microsoft {COCO}: Common Objects in Context},
   author = {Tsung-Yi Lin and Michael Maire and Serge Belongie and
                  James Hays and Pietro Perona and Deva Ramanan and
                  Piotr Doll{\'a}r and C. Lawrence Zitnick},
   booktitle = {European Conference on Computer Vision (ECCV)},
   year = {2014}
}

@inproceedings{Dalal2006,
 author = {Dalal, Navneet and Triggs, Bill and Schmid, Cordelia},
 title = {Human Detection Using Oriented Histograms of Flow and Appearance},
 booktitle = {Proceedings of the 9th European Conference on Computer Vision - Volume Part II},
 series = {ECCV'06},
 year = {2006},
 isbn = {3-540-33834-9, 978-3-540-33834-5},
 location = {Graz, Austria},
 pages = {428--441},
 numpages = {14},
 url = {http://dx.doi.org/10.1007/11744047_33},
 doi = {10.1007/11744047_33},
 acmid = {2168522},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@inproceedings{Papineni:BLEU,
 author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
 title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
 booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
 series = {ACL '02},
 year = {2002},
 location = {Philadelphia, Pennsylvania},
 pages = {311--318},
 numpages = {8},
 url = {http://dx.doi.org/10.3115/1073083.1073135},
 doi = {10.3115/1073083.1073135},
 acmid = {1073135},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{denkowski-lavie:2014:Meteor,
 author    = {Denkowski, Michael  and  Lavie, Alon},
 title     = {Meteor Universal: Language Specific Translation Evaluation for Any Target Language},
 booktitle = {Proceedings of the Ninth Workshop on Statistical Machine Translation},
 month     = {June},
 year      = {2014},
 address   = {Baltimore, Maryland, USA},
 publisher = {Association for Computational Linguistics},
 pages     = {376--380},
 url       = {http://www.aclweb.org/anthology/W14-3348}
}

@article{lin2004rouge,
 title={Rouge: A package for automatic evaluation of summaries},
 author={Lin, Chin-Yew},
 journal={Text summarization branches out: Proceedings of the ACL-04 workshop},
 volume={8},
 year={2004}
}

@InProceedings{Vedantam_2015_CVPR,
 author = {Vedantam, Ramakrishna and Lawrence Zitnick, C. and Parikh, Devi},
 title = {CIDEr: Consensus-Based Image Description Evaluation},
 booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
 month = {June},
 year = {2015}
}

@article{ren15fasterrcnn,
  Author =	 {Shaoqing Ren and Kaiming He and Ross Girshick and
                  Jian Sun},
  Title =	 {{Faster R-CNN}: Towards Real-Time Object Detection
                  with Region Proposal Networks},
  Journal =	 {arXiv preprint arXiv:1506.01497},
  Year =	 {2015}
}

@article{He2015,
    author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
    title = {Deep Residual Learning for Image Recognition},
    journal = {arXiv preprint arXiv:1512.03385},
    year = {2015}
}

@incollection{Zhou2014NIPS,
  title =	 {Learning Deep Features for Scene Recognition using
                  Places Database},
  author =	 {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong
                  and Torralba, Antonio and Oliva, Aude},
  booktitle =	 {Advances in Neural Information Processing Systems
                  27},
  editor =	 {Z. Ghahramani and M. Welling and C. Cortes and
                  N. D. Lawrence and K. Q. Weinberger},
  pages =	 {487--495},
  year =	 {2014},
  publisher =	 {Curran Associates, Inc.},
  url =
                  {http://papers.nips.cc/paper/5349-learning-deep-features-for-scene-recognition-using-places-database.pdf}
}
@MISC{Bastien-Theano-2012,
  author = {Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Bergstra, James and Goodfellow, Ian J. and Bergeron, Arnaud and Bouchard, Nicolas and Bengio, Yoshua},
  title = {Theano: new features and speed improvements},
  year = {2012},
  howpublished = {Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop},
  abstract = {Theano is a linear algebra compiler that optimizes a user’s symbolically-speciﬁed
  mathematical computations to produce efﬁcient low-level implementations. In
  this paper, we present new features and efﬁciency improvements to Theano, and
  benchmarks demonstrating Theano’s performance relative to Torch7, a recently
  introduced machine learning library, and to RNNLM, a C++ library targeted at
  recurrent neural networks.}
}
@INPROCEEDINGS{bergstra+al:2010-scipy,
  author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
  month = jun,
  title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
  year = {2010},
  location = {Austin, TX},
  note = {Oral Presentation},
  abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@article{ZarembaSV14,
  author    = {Wojciech Zaremba and
               Ilya Sutskever and
               Oriol Vinyals},
  title     = {Recurrent Neural Network Regularization},
  journal   = {CoRR},
  volume    = {abs/1409.2329},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.2329},
  timestamp = {Wed, 01 Oct 2014 15:00:04 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ZarembaSV14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@InProceedings{kim:2014:CNNsent,
  author    = {Kim, Yoon},
  title     = {Convolutional Neural Networks for Sentence Classification},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = {October},
  year      = {2014},
  address   = {Doha, Qatar},
  publisher = {Association for Computational Linguistics},
  pages     = {1746--1751},
  url       = {http://www.aclweb.org/anthology/D14-1181}
}

@article{you2016image,
  title={Image Captioning with Semantic Attention},
  author={You, Quanzeng and Jin, Hailin and Wang, Zhaowen and Fang, Chen and Luo, Jiebo},
  journal={arXiv preprint arXiv:1603.03925},
  year={2016}
}
@Misc{rmspropTielman,
  author = {Tieleman, Tijmen and Hinton, Geoffrey},
  title  = {Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  year   = {2012},
  howpublished= {\emph{COURSERA}: Neural Networks for Machine Learning}
}

@Misc{lsun2015CaptionSlides,
  author = {Cui, Yin and Ruggero Ronchi, Matteo  and Lin, Tsung-Yi},
  title  = {1st Captioning Challenge Slides },
  year   = {2015},
  howpublished= {Large-scale Scene UNderstanding Workshop},
  url = {http://lsun.cs.princeton.edu/slides/caption_open.pdf}
}

@article{kiros2014unifying,
  title={Unifying visual-semantic embeddings with multimodal neural language models},
  author={Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Richard S},
  journal={arXiv preprint arXiv:1411.2539},
  year={2014}
}
@inproceedings{kiros2014multimodal,
  title={Multimodal neural language models},
  author={Kiros, Ryan and Salakhutdinov, Ruslan and Zemel, Rich},
  booktitle={Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
  pages={595--603},
  year={2014}
}

@manual{ThousandQuote,
  title  = "A picture is worth a thousand words",
  url    = {https://en.wikipedia.org/wiki/A_picture_is_worth_a_thousand_words},
  year   = "2016 (accessed June 23, 2016)"
}
@manual{InstStats,
  title  = "Instagram Statistics",
  url    = {https://www.instagram.com/press},
  year   = "2016 (accessed June 23, 2016)"
}
@manual{YouStats,
  title  = "Hours of video uploaded to YouTube every minute as of July 2015 ",
  url    = {http://www.statista.com/statistics/259477/hours-of-video-uploaded-to-youtube-every-minute/},
  year   = "2016 (accessed June 23, 2016)"
}

@article{ILSVRC15,
  Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  Title = {{ImageNet Large Scale Visual Recognition Challenge}},
  Year = {2015},
  journal  = {International Journal of Computer Vision (IJCV)},
  doi = {10.1007/s11263-015-0816-y},
  volume={115},
  number={3},
  pages={211-252}
}

@INPROCEEDINGS{ImagenetOrig, 
  author={J. Deng and W. Dong and R. Socher and L. J. Li and Kai Li and Li Fei-Fei}, 
  booktitle={Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009}, 
  pages={248-255}, 
  keywords={Internet;computer vision;image resolution;image retrieval;multimedia computing;ontologies (artificial intelligence);trees (mathematics);very large databases;visual databases;ImageNet database;Internet;computer vision;image resolution;image retrieval;large-scale hierarchical image database;large-scale ontology;multimedia data;subtree;wordNet structure;Explosions;Image databases;Image retrieval;Information retrieval;Internet;Large-scale systems;Multimedia databases;Ontologies;Robustness;Spine}, 
  doi={10.1109/CVPR.2009.5206848}, 
  ISSN={1063-6919}, 
  month={June},
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1026--1034},
  year={2015}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in neural information processing systems},
  pages={3320--3328},
  year={2014}
}

@InProceedings{Donahue2014,
  author = 	 {Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman 
                  and Ning Zhang and Eric Tzeng and Trevor Darrell}, 
  title = 	 {{DeCAF}: {A} Deep Convolutional Activation Feature for Generic Visual Recognition},
  booktitle = {ICML 2014},
  year = 	 2014}

@InProceedings{Razavian2014CVPR,
  author =	 {Sharif Razavian, Ali and Azizpour, Hossein and
                  Sullivan, Josephine and Carlsson, Stefan},
  title =	 {CNN Features Off-the-Shelf: An Astounding Baseline
                  for Recognition},
  booktitle =	 {The IEEE Conference on Computer Vision and Pattern
                  Recognition (CVPR) Workshops},
  month =	 {June},
  year =	 {2014}
}

@InProceedings{Krizhevsky2012,
 title ={{ImageNet} Classification with Deep Convolutional Neural Networks},
 author={Alex Krizhevsky and Ilya Sutskever and Geoff Hinton},
 booktitle = {NIPS},
 year = {2012},
}

@Unpublished{Gong2014,
  author    = {Yunchao Gong and
               Liwei Wang and
               Ruiqi Guo and
               Svetlana Lazebnik},
  title     = {Multi-scale Orderless Pooling of Deep Convolutional Activation
               Features},
  year      = 2014,
  note        = {arXiv.org:1403.1840},
  month = 	 {March},
}

@inproceedings{Vedaldi2010,
  Author    = {A. Vedaldi and A. Zisserman},
  Title     = {Efficient Additive Kernels via
               Explicit Feature Maps},
  Booktitle = {Proceedings of the IEEE Conf. on
               Computer Vision and Pattern Recognition (CVPR 2010)},
  Year      = 2010
}

@ARTICLE{Vedaldi2012,
  author={Vedaldi, A. and Zisserman, A.},
  journal={Pattern Analysis and Machine Intelligence, IEEE Transactions on}, 
  title={Efficient Additive Kernels via Explicit Feature Maps},
  year={2012},
  month={march},
  volume={34},
  number={3},
  pages={480 -492},
  doi={10.1109/TPAMI.2011.153},
  ISSN={0162-8828},
}

@INPROCEEDINGS{Vedaldi2009,
author={Vedaldi, A. and Gulshan, V. and Varma, M. and Zisserman, A.},
booktitle={Computer Vision, 2009 IEEE 12th International Conference on}, 
title={Multiple kernels for object detection},
year={2009},
month={oct},
pages={606 -613},
doi={10.1109/ICCV.2009.5459183},
ISSN={1550-5499},
}

@inproceedings{venugopalan2015sequence,
  title={Sequence to sequence-video to text},
  author={Venugopalan, Subhashini and Rohrbach, Marcus and Donahue, Jeffrey and Mooney, Raymond and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4534--4542},
  year={2015}
}
@inproceedings{Xu:CVPR16,
title={MSR-VTT: A Large Video Description Dataset for Bridging Video and Language},
author={Jun Xu and Tao Mei and Ting Yao and Yong Rui},
booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2016}
}

@inproceedings{KarpathyCVPR14,
  title     = {Large-scale Video Classification with Convolutional Neural Networks},
  author    = {Andrej Karpathy and George Toderici and Sanketh Shetty and Thomas Leung and Rahul Sukthankar and Li Fei-Fei},
  year      = {2014},
  booktitle = {CVPR}
}

@ARTICLE{3dCNN_ji2013,
author={S. Ji and W. Xu and M. Yang and K. Yu},
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
title={3D Convolutional Neural Networks for Human Action Recognition},
year={2013},
volume={35},
number={1},
pages={221-231},
doi={10.1109/TPAMI.2012.59},
ISSN={0162-8828},
month={Jan},
}

@misc{CocoChallengeSlides,
    title  = "Microsoft COCO 1st Captioning Challenge",
    author = {Yin Cuiand Matteo Ruggero and Ronchi and Tsung-Yi Lin},
    Howpublished = {\url{http://lsun.cs.princeton.edu/slides/caption_open.pdf}},
    url    = {http://lsun.cs.princeton.edu/slides/caption_open.pdf},
    year   = "2016 (accessed July 1, 2016)"
}

@article{Xu2015show,
    title={Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
    author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
    journal={arXiv preprint},
    volume= {abs/1502.03044},
    year={2015}
}
@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  CommentThispages={2625--2634},
  year={2015}
}

@article{DBLP:C3D,
  author    = {Du Tran and
               Lubomir D. Bourdev and
               Rob Fergus and
               Lorenzo Torresani and
               Manohar Paluri},
  title     = {{C3D:} Generic Features for Video Analysis},
  journal   = {arXiv},
  volume    = {abs/1412.0767},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.0767},
  timestamp = {Thu, 01 Jan 2015 19:51:08 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/TranBFTP14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@inproceedings{Wang2013,
  author={Heng Wang and Cordelia Schmid},
  title={Action Recognition with Improved Trajectories},
  booktitle= {IEEE International Conference on Computer Vision},
  year={2013},
  url={http://hal.inria.fr/hal-00873267}
}

@article{DBLP:journals/corr/RohrbachTRTPLCS16,
  author    = {Anna Rohrbach and
               Atousa Torabi and
               Marcus Rohrbach and
               Niket Tandon and
               Christopher J. Pal and
               Hugo Larochelle and
               Aaron C. Courville and
               Bernt Schiele},
  title     = {Movie Description},
  journal   = {arXiv},
  volume    = {abs/1605.03705},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.03705},
  timestamp = {Wed, 01 Jun 2016 15:51:08 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/RohrbachTRTPLCS16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@inproceedings{bridgevideolanguage-Pan,
author = {Yingwei Pan and Tao Mei and Ting Yao and Houqiang Li and Yong Rui},
title = {Jointly Modeling Embedding and Translation to Bridge Video and Language},
booktitle={IEEE International Conference on Computer Vision and Pattern Recognition},
year = {2016},
month = {June},
publisher = {IEEE – Institute of Electrical and Electronics Engineers},
url = {https://www.microsoft.com/en-us/research/publication/jointly-modeling-embedding-and-translation-to-bridge-video-and-language-2/},
}

@article{LIBSVM,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 volume = {2},
 issue = {3},
 year = {2011},
 pages = {27:1--27:27}
}

@INPROCEEDINGS{Xiao2010,
  author={Jianxiong Xiao and Hays, J. and Ehinger, K.A. and Oliva, A. and Torralba, A.},
  booktitle={Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on},
  title={{SUN} database: {L}arge-scale scene recognition from abbey to zoo},
  year=2010,
  month={June},
  pages={3485-3492},
  doi={10.1109/CVPR.2010.5539970}
}

@Article{Xiao2014,
author="Xiao, Jianxiong
and Ehinger, Krista A.
and Hays, James
and Torralba, Antonio
and Oliva, Aude",
title="SUN Database: Exploring a Large Collection of Scene Categories",
journal="International Journal of Computer Vision",
year="2014",
pages="1--20",
Abstract="Progress in scene understanding requires reasoning about the
                  rich and diverse visual environments that make up
                  our daily experience. To this end, we propose the
                  Scene Understanding database, a nearly exhaustive
                  collection of scenes categorized at the same level
                  of specificity as human discourse. The database
                  contains 908 distinct scene categories and 131,072
                  images. Given this data with both scene and object
                  labels available, we perform in-depth analysis of
                  co-occurrence statistics and the contextual
                  relationship. To better understand this large scale
                  taxonomy of scene categories, we perform two human
                  experiments: we quantify human scene recognition
                  accuracy, and we measure how typical each image is
                  of its assigned scene category. Next, we perform
                  computational experiments: scene recognition with
                  global image features, indoor versus outdoor
                  classification, and ``scene detection,'' in which we
                  relax the assumption that one image depicts only one
                  scene category. Finally, we relate human experiments
                  to machine performance and explore the relationship
                  between human and machine recognition errors and the
                  relationship between image ``typicality'' and
                  machine recognition accuracy.",
issn="1573-1405",
doi="10.1007/s11263-014-0748-y",
url="http://dx.doi.org/10.1007/s11263-014-0748-y"
}

@ARTICLE{Li2013,
  author = {Xirong Li and Cees G. M. Snoek and Marcel Worring and Dennis C. Koelma and Arnold W. M. Smeulders},
  title = {Bootstrapping Visual Categorization with Relevant Negatives},
  journal = {{IEEE} Transactions on Multimedia},
  pages = {933--945},
  month = {June},
  year = 2013,
  volume = 15,
  number = 4
}

